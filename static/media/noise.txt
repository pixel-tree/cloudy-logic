The greatest obstacle to discovery is not ignorance – it is the illusion of knowledge. (Daniel J. Boorstin) 
Briefly, let us return to the Hubble Deep Field.
The world is made up of stories: representations, built on assumptions, beliefs, axioms; and as we focus only on what we attend to, some things are inevitably left unconsidered.
The underlying narrative that forms a basis for this introduction is one of Western science: a postulate that phenomena are independent of the observer.
Therefore, we can devise information communication technologies by manipulating arbitrary physical objects into semantically meaningful things.
However, this is problematic: firstly, information is ambiguous (its perception nonuniform, subjective); and secondly, the instruments with which we collect and process data emerge from axiomatised knowledge—propositions and belief systems that, despite their usefulness, at the very least implicitly subscribe to an ethico-onto-epistemological position of some sort.
The use of a technology is in one sense an endorsement of its epistemic disposition (whether intentional or not). Consequently, in some situations the medium truly is the message: the way in which information is communicated might evoke more meaning than the content itself. In other words, data describing data—metadata—might be more insightful in characterising the system.
The Hubble Extreme Deep Field, much like the RGB colour model and other monumental artefacts of the advances in our theory of knowledge, allow us to capture fragments of spacetime and examine them in closer detail; although echoing canonical narratives predominant in scientific research: determinism (future uniquely follows from the present); realism (there exists a real world out there independent of the observer); and physicalism (everything that exists is physical).
To dispute these axioms is unnecessary for now, as we would be inevitably left to dwell on the greatest mysteries of the universe; whereas, the purpose of this narrative is much simpler: to question the mechanisms of knowledge production in relation to data practices, and reflect on whether we recognise the feedback loops which we might be responsible for initiating.
It may be easy to take knowledge for granted because, after all, we are often distanced from its production. For example, something like the Hubble Deep Field might feel phenomenally intangible and rather impossible to discuss without relevant expertise; but a snapshot like this is fertile ground for philosophical analysis.
As a representation of something, it is crucial to consider the image as a system of knowledge: what assumptions have been made to synthesise this information? How accurately do representations generally represent the state of our reality? For whom is our reality produced and why? And how is this relevant in the contexts of machine learning and AI?